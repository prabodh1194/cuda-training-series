{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Cuda Practice in C"
      ],
      "metadata": {
        "id": "DwTj4-WP9gk3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3Q1WOx0D41Hj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "UJUdTG059mpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile stencil_1d.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <algorithm>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "#define N 4096\n",
        "#define RADIUS 3\n",
        "#define BLOCK_SIZE 16\n",
        "\n",
        "__global__ void stencil_1d(int *in, int *out) {\n",
        "    __shared__ int temp[2 * RADIUS + BLOCK_SIZE];\n",
        "    int gindex = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    int lindex = threadIdx.x + RADIUS;\n",
        "\n",
        "    // Read input elements into shared memory\n",
        "    temp[lindex] = in[gindex];\n",
        "    if (threadIdx.x < RADIUS) {\n",
        "      temp[lindex - RADIUS] = in[gindex - RADIUS];\n",
        "      temp[lindex + BLOCK_SIZE] = in[gindex + BLOCK_SIZE];\n",
        "    }\n",
        "\n",
        "    // Synchronize (ensure all the data is available)\n",
        "    __syncthreads();\n",
        "\n",
        "    // Apply the stencil\n",
        "    int result = 0;\n",
        "    for (int offset = -RADIUS; offset <= RADIUS; offset++)\n",
        "      result += temp[lindex + offset];\n",
        "\n",
        "    // Store the result\n",
        "    out[gindex] = result;\n",
        "}\n",
        "\n",
        "void fill_ints(int *x, int n) {\n",
        "  fill_n(x, n, 1);\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "  int *in, *out; // host copies of a, b, c\n",
        "  int *d_in, *d_out; // device copies of a, b, c\n",
        "\n",
        "  // Alloc space for host copies and setup values\n",
        "  int size = (N + 2 * RADIUS) * sizeof(int);\n",
        "  in = (int *)malloc(size); fill_ints(in, N + 2*RADIUS);\n",
        "  out = (int *)malloc(size); fill_ints(out, N + 2*RADIUS);\n",
        "\n",
        "  // Alloc space for device copies\n",
        "  cudaMalloc((void **)&d_in, size);\n",
        "  cudaMalloc((void **)&d_out, size);\n",
        "\n",
        "  // Copy to device\n",
        "  cudaMemcpy(d_in, in, size, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_out, out, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "  // Launch stencil_1d() kernel on GPU\n",
        "  stencil_1d<<<N/BLOCK_SIZE,BLOCK_SIZE>>>(d_in + RADIUS, d_out + RADIUS);\n",
        "\n",
        "  // Copy result back to host\n",
        "  cudaMemcpy(out, d_out, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "  // Error Checking\n",
        "  for (int i = 0; i < N + 2*RADIUS; i++) {\n",
        "    if (i<RADIUS || i>=N+RADIUS){\n",
        "      if (out[i] != 1)\n",
        "    \tprintf(\"Mismatch at index %d, was: %d, should be: %d\\n\", i, out[i], 1);\n",
        "    } else {\n",
        "      if (out[i] != 1 + 2*RADIUS)\n",
        "    \tprintf(\"Mismatch at index %d, was: %d, should be: %d\\n\", i, out[i], 1 + 2*RADIUS);\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // Cleanup\n",
        "  free(in); free(out);\n",
        "  cudaFree(d_in); cudaFree(d_out);\n",
        "  printf(\"Success!\\n\");\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "Ze3e2G5G95SZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile\n",
        "!nvcc -arch=sm_75 stencil_1d.cu -o stencil_1d\n",
        "\n",
        "# Run\n",
        "!./stencil_1d"
      ],
      "metadata": {
        "id": "JanGWqdN9_CY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile tiled_matmul.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "// these are just for timing measurments\n",
        "#include <time.h>\n",
        "\n",
        "// error checking macro\n",
        "#define cudaCheckErrors(msg) \\\n",
        "    do { \\\n",
        "        cudaError_t __err = cudaGetLastError(); \\\n",
        "        if (__err != cudaSuccess) { \\\n",
        "            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\\n\", \\\n",
        "                msg, cudaGetErrorString(__err), \\\n",
        "                __FILE__, __LINE__); \\\n",
        "            fprintf(stderr, \"*** FAILED - ABORTING\\n\"); \\\n",
        "            exit(1); \\\n",
        "        } \\\n",
        "    } while (0)\n",
        "\n",
        "\n",
        "const int DSIZE = 8192;\n",
        "const int block_size = 32;  // CUDA maximum is 1024 *total* threads in block\n",
        "const float A_val = 3.0f;\n",
        "const float B_val = 2.0f;\n",
        "\n",
        "// matrix multiply (naive) kernel: C = A * B\n",
        "__global__ void mmul(const float *A, const float *B, float *C, int ds) {\n",
        "\n",
        "  // declare cache in shared memory\n",
        "  __shared__ float As[block_size][block_size];\n",
        "  __shared__ float Bs[block_size][block_size];\n",
        "\n",
        "  int idx = threadIdx.x+blockDim.x*blockIdx.x; // create thread x index\n",
        "  int idy = threadIdx.y+blockDim.y*blockIdx.y; // create thread y index\n",
        "\n",
        "  if ((idx < ds) && (idy < ds)){\n",
        "    float temp = 0;\n",
        "    for (int i = 0; i < ds/block_size; i++) { // multiplication happens in multiple phases.\n",
        "\n",
        "      // Load data into shared memory\n",
        "      As[threadIdx.y][threadIdx.x] = A[idy * ds + (i * block_size + threadIdx.x)]; // A[idy][]\n",
        "      Bs[threadIdx.y][threadIdx.x] = B[(i * block_size + threadIdx.y) * ds + idx];  // B[][idx]\n",
        "\n",
        "      // Synchronize\n",
        "      __syncthreads();\n",
        "\n",
        "      // Keep track of the running sum\n",
        "      for (int k = 0; k < block_size; k++)\n",
        "      \ttemp += As[threadIdx.y][k] * Bs[k][threadIdx.x]; // dot product of row and column\n",
        "      __syncthreads();\n",
        "\n",
        "    }\n",
        "\n",
        "    // Write to global memory\n",
        "    C[idy*ds+idx] = temp;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "\n",
        "  float *h_A, *h_B, *h_C, *d_A, *d_B, *d_C;\n",
        "\n",
        "\n",
        "  // these are just for timing\n",
        "  clock_t t0, t1, t2;\n",
        "  double t1sum=0.0;\n",
        "  double t2sum=0.0;\n",
        "\n",
        "  // start timing\n",
        "  t0 = clock();\n",
        "\n",
        "  h_A = new float[DSIZE*DSIZE];\n",
        "  h_B = new float[DSIZE*DSIZE];\n",
        "  h_C = new float[DSIZE*DSIZE];\n",
        "  for (int i = 0; i < DSIZE*DSIZE; i++){\n",
        "    h_A[i] = A_val;\n",
        "    h_B[i] = B_val;\n",
        "    h_C[i] = 0;}\n",
        "\n",
        "  // Initialization timing\n",
        "  t1 = clock();\n",
        "  t1sum = ((double)(t1-t0))/CLOCKS_PER_SEC;\n",
        "  printf(\"Init took %f seconds.  Begin compute\\n\", t1sum);\n",
        "\n",
        "  // Allocate device memory and copy input data over to GPU\n",
        "  cudaMalloc(&d_A, DSIZE*DSIZE*sizeof(float));\n",
        "  cudaMalloc(&d_B, DSIZE*DSIZE*sizeof(float));\n",
        "  cudaMalloc(&d_C, DSIZE*DSIZE*sizeof(float));\n",
        "  cudaCheckErrors(\"cudaMalloc failure\");\n",
        "  cudaMemcpy(d_A, h_A, DSIZE*DSIZE*sizeof(float), cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_B, h_B, DSIZE*DSIZE*sizeof(float), cudaMemcpyHostToDevice);\n",
        "  cudaCheckErrors(\"cudaMemcpy H2D failure\");\n",
        "\n",
        "  // Cuda processing sequence step 1 is complete\n",
        "\n",
        "  // Launch kernel\n",
        "  dim3 block(block_size, block_size);  // dim3 variable holds 3 dimensions\n",
        "  dim3 grid((DSIZE+block.x-1)/block.x, (DSIZE+block.y-1)/block.y);\n",
        "  mmul<<<grid, block>>>(d_A, d_B, d_C, DSIZE);\n",
        "  cudaCheckErrors(\"kernel launch failure\");\n",
        "\n",
        "  // Cuda processing sequence step 2 is complete\n",
        "\n",
        "  // Copy results back to host\n",
        "  cudaMemcpy(h_C, d_C, DSIZE*DSIZE*sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "  // GPU timing\n",
        "  t2 = clock();\n",
        "  t2sum = ((double)(t2-t1))/CLOCKS_PER_SEC;\n",
        "  printf (\"Done. Compute took %f seconds\\n\", t2sum);\n",
        "\n",
        "  // Cuda processing sequence step 3 is complete\n",
        "\n",
        "  // Verify results\n",
        "  cudaCheckErrors(\"kernel execution failure or cudaMemcpy H2D failure\");\n",
        "  for (int i = 0; i < DSIZE*DSIZE; i++) if (h_C[i] != A_val*B_val*DSIZE) {printf(\"mismatch at index %d, was: %f, should be: %f\\n\", i, h_C[i], A_val*B_val*DSIZE); return -1;}\n",
        "  printf(\"Success!\\n\");\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "9b5wnj0rKMoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 tiled_matmul.cu -o tiled_matmul\n",
        "\n",
        "!./tiled_matmul"
      ],
      "metadata": {
        "id": "WUKkAG-DKWGB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}