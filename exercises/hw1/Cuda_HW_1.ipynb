{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Cuda Practice in C++ - HW - 1"
      ],
      "metadata": {
        "id": "DwTj4-WP9gk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "UJUdTG059mpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile hello_cuda.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void hello(){\n",
        "  printf(\"Hello from block: %u, thread: %u\\n\", blockIdx.x, threadIdx.x);\n",
        "}\n",
        "\n",
        "int main(){\n",
        "\n",
        "  printf(\"launching kernel\\n\");\n",
        "  hello<<<2, 2>>>();\n",
        "\n",
        "  // Check for kernel launch errors\n",
        "  cudaError_t err = cudaGetLastError();\n",
        "\n",
        "  printf(\"%s\\n\", cudaGetErrorString(err));\n",
        "\n",
        "  err = cudaDeviceSynchronize();\n",
        "\n",
        "  printf(\"%s\\n\", cudaGetErrorString(err));\n",
        "\n",
        "  return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "Ze3e2G5G95SZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile\n",
        "!nvcc -arch=sm_75 hello_cuda.cu -o hello_cuda\n",
        "\n",
        "# Run\n",
        "!./hello_cuda"
      ],
      "metadata": {
        "id": "JanGWqdN9_CY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_add.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "// error checking macro\n",
        "#define cudaCheckErrors(msg) \\\n",
        "    do { \\\n",
        "        cudaError_t __err = cudaGetLastError(); \\\n",
        "        if (__err != cudaSuccess) { \\\n",
        "            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\\n\", \\\n",
        "                msg, cudaGetErrorString(__err), \\\n",
        "                __FILE__, __LINE__); \\\n",
        "            fprintf(stderr, \"*** FAILED - ABORTING\\n\"); \\\n",
        "            exit(1); \\\n",
        "        } \\\n",
        "    } while (0)\n",
        "\n",
        "\n",
        "const int DSIZE = 4096;\n",
        "const int block_size = 256;  // CUDA maximum is 1024\n",
        "// vector add kernel: C = A + B\n",
        "__global__ void vadd(const float *A, const float *B, float *C, int ds){\n",
        "\n",
        "  int idx = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  // printf(\"%d %d %d %d %d %d\\n\", blockDim.x, blockDim.y, blockIdx.x, blockIdx.y, threadIdx.x, threadIdx.y);\n",
        "  if (idx < ds)\n",
        "    C[idx] = A[idx] + B[idx];\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  float *h_A, *h_B, *h_C, *d_A, *d_B, *d_C;\n",
        "\n",
        "  h_A = new float[DSIZE];  // allocate space for vectors in host memory\n",
        "  h_B = new float[DSIZE];\n",
        "  h_C = new float[DSIZE];\n",
        "\n",
        "  for (int i = 0; i < DSIZE; i++){  // initialize vectors in host memory\n",
        "    h_A[i] = rand()/(float)RAND_MAX;\n",
        "    h_B[i] = rand()/(float)RAND_MAX;\n",
        "    h_C[i] = 0;\n",
        "}\n",
        "\n",
        "  cudaMalloc(&d_A, DSIZE*sizeof(float));  // allocate device space for vector A\n",
        "  cudaMalloc(&d_B, DSIZE*sizeof(float));  // allocate device space for vector A\n",
        "  cudaMalloc(&d_C, DSIZE*sizeof(float));  // allocate device space for vector A\n",
        "\n",
        "  cudaCheckErrors(\"cudaMalloc failure\"); // error checking\n",
        "  // copy vector A to device:\n",
        "  cudaMemcpy(d_A, h_A, DSIZE*sizeof(float), cudaMemcpyHostToDevice);\n",
        "  // copy vector B to device:\n",
        "  cudaMemcpy(d_B, h_B, DSIZE*sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "  cudaCheckErrors(\"cudaMemcpy H2D failure\");\n",
        "  //cuda processing sequence step 1 is complete\n",
        "  vadd<<<(DSIZE+block_size-1)/block_size, block_size>>>(d_A, d_B, d_C, DSIZE);\n",
        "  cudaCheckErrors(\"kernel launch failure\");\n",
        "  //cuda processing sequence step 2 is complete\n",
        "\n",
        "  // copy vector C from device to host:\n",
        "  cudaMemcpy(h_C, d_C, DSIZE*sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "  //cuda processing sequence step 3 is complete\n",
        "  cudaCheckErrors(\"kernel execution failure or cudaMemcpy H2D failure\");\n",
        "  printf(\"A[0] = %f\\n\", h_A[0]);\n",
        "  printf(\"B[0] = %f\\n\", h_B[0]);\n",
        "  printf(\"C[0] = %f\\n\", h_C[0]);\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27865c50-07fd-42ba-881f-a6c2060c52f5",
        "id": "9b5wnj0rKMoE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting vector_add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 vector_add.cu -o vector_add\n",
        "\n",
        "!./vector_add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUKkAG-DKWGB",
        "outputId": "cb996122-8c40-4d44-f9b3-24228ad4bad8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A[0] = 0.840188\n",
            "B[0] = 0.394383\n",
            "C[0] = 1.234571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_mul.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "// these are just for timing measurments\n",
        "#include <time.h>\n",
        "\n",
        "// error checking macro\n",
        "#define cudaCheckErrors(msg) \\\n",
        "    do { \\\n",
        "        cudaError_t __err = cudaGetLastError(); \\\n",
        "        if (__err != cudaSuccess) { \\\n",
        "            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\\n\", \\\n",
        "                msg, cudaGetErrorString(__err), \\\n",
        "                __FILE__, __LINE__); \\\n",
        "            fprintf(stderr, \"*** FAILED - ABORTING\\n\"); \\\n",
        "            exit(1); \\\n",
        "        } \\\n",
        "    } while (0)\n",
        "\n",
        "\n",
        "const int DSIZE = 4096;\n",
        "const int block_size = 16;  // CUDA maximum is 1024 *total* threads in block\n",
        "const float A_val = 1.0f;\n",
        "const float B_val = 2.0f;\n",
        "\n",
        "// matrix multiply (naive) kernel: C = A * B\n",
        "__global__ void mmul(const float *A, const float *B, float *C, int ds) {\n",
        "\n",
        "  int idx = threadIdx.x+blockDim.x*blockIdx.x; // create thread x index\n",
        "  int idy = threadIdx.y+blockDim.y*blockIdx.y; // create thread y index\n",
        "\n",
        "  if ((idx < ds) && (idy < ds)){\n",
        "    float temp = 0;\n",
        "    int r = idy * ds;\n",
        "    for (int i = 0; i < ds; i++)\n",
        "      temp += A[r + i] * B[i * ds + idx];   // dot product of row and column\n",
        "    C[idy*ds+idx] = temp;\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "\n",
        "  float *h_A, *h_B, *h_C, *d_A, *d_B, *d_C;\n",
        "\n",
        "  // these are just for timing\n",
        "  clock_t t0, t1, t2;\n",
        "  double t1sum=0.0;\n",
        "  double t2sum=0.0;\n",
        "\n",
        "  // start timing\n",
        "  t0 = clock();\n",
        "\n",
        "  h_A = new float[DSIZE*DSIZE];\n",
        "  h_B = new float[DSIZE*DSIZE];\n",
        "  h_C = new float[DSIZE*DSIZE];\n",
        "\n",
        "  for (int i = 0; i < DSIZE*DSIZE; i++){\n",
        "    h_A[i] = A_val;\n",
        "    h_B[i] = B_val;\n",
        "    h_C[i] = 0;\n",
        "}\n",
        "\n",
        "  // Initialization timing\n",
        "  t1 = clock();\n",
        "  t1sum = ((double)(t1-t0))/CLOCKS_PER_SEC;\n",
        "  printf(\"Init took %f seconds.  Begin compute\\n\", t1sum);\n",
        "\n",
        "  // Allocate device memory and copy input data over to GPU\n",
        "  cudaMalloc(&d_A, DSIZE*DSIZE*sizeof(float));\n",
        "  cudaMalloc(&d_B, DSIZE*DSIZE*sizeof(float));\n",
        "  cudaMalloc(&d_C, DSIZE*DSIZE*sizeof(float));\n",
        "  cudaCheckErrors(\"cudaMalloc failure\");\n",
        "  cudaMemcpy(d_A, h_A, DSIZE*DSIZE*sizeof(float), cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_B, h_B, DSIZE*DSIZE*sizeof(float), cudaMemcpyHostToDevice);\n",
        "  cudaCheckErrors(\"cudaMemcpy H2D failure\");\n",
        "\n",
        "  // Cuda processing sequence step 1 is complete\n",
        "\n",
        "  // Launch kernel\n",
        "  dim3 block(block_size, block_size);  // dim3 variable holds 3 dimensions\n",
        "  dim3 grid((DSIZE+block.x-1)/block.x, (DSIZE+block.y-1)/block.y);\n",
        "  mmul<<<grid, block>>>(d_A, d_B, d_C, DSIZE);\n",
        "  cudaCheckErrors(\"kernel launch failure\");\n",
        "\n",
        "  // Cuda processing sequence step 2 is complete\n",
        "\n",
        "  // Copy results back to host\n",
        "  cudaMemcpy(h_C, d_C, DSIZE*DSIZE*sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "  // GPU timing\n",
        "  t2 = clock();\n",
        "  t2sum = ((double)(t2-t1))/CLOCKS_PER_SEC;\n",
        "  printf (\"Done. Compute took %f seconds\\n\", t2sum);\n",
        "\n",
        "  // Cuda processing sequence step 3 is complete\n",
        "\n",
        "  // Verify results\n",
        "  cudaCheckErrors(\"kernel execution failure or cudaMemcpy H2D failure\");\n",
        "  for (int i = 0; i < DSIZE*DSIZE; i++) if (h_C[i] != A_val*B_val*DSIZE) {printf(\"mismatch at index %d, was: %f, should be: %f\\n\", i, h_C[i], A_val*B_val*DSIZE); return -1;}\n",
        "  printf(\"Success!\\n\");\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "myMfpXyBZPaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "351d8ad4-7881-42fb-d79f-994b47d3a99c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrix_mul.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 matrix_mul.cu -o matrix_mul\n",
        "\n",
        "!./matrix_mul"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_B5g9hh1lO8f",
        "outputId": "bb03e4b3-b3cb-43ed-9844-1264d4cd7415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Init took 0.131690 seconds.  Begin compute\n",
            "Done. Compute took 0.534703 seconds\n",
            "Success!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}